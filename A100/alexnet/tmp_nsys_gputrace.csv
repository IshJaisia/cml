Start(sec),Duration(nsec),CorrId,GrdX,GrdY,GrdZ,BlkX,BlkY,BlkZ,Reg/Trd,StcSMem,DymSMem,Bytes,Thru(MB/s),SrcMemKd,DstMemKd,Device,Ctx,Strm,Name
11.738068,11711,131,,,,,,,,,,92928,7935.104,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
11.739387,2144,143,,,,,,,,,,256,119.403,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
11.740123,107424,159,,,,,,,,,,1228800,11438.785,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
11.740457,2176,171,,,,,,,,,,768,352.941,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
11.740772,413567,183,,,,,,,,,,2654208,6417.843,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
11.741371,2240,195,,,,,,,,,,1536,685.714,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
11.741676,657759,207,,,,,,,,,,3538944,5380.305,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
11.742624,2208,219,,,,,,,,,,1024,463.768,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
11.742950,343264,231,,,,,,,,,,2359296,6873.124,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
11.743545,2208,243,,,,,,,,,,1024,463.768,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
11.744675,35297215,270,,,,,,,,,,150994944,4277.815,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
11.780491,3264,283,,,,,,,,,,16384,5019.608,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
11.781127,15582435,300,,,,,,,,,,67108864,4306.699,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
11.797129,3328,313,,,,,,,,,,16384,4923.077,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
11.797727,3732377,330,,,,,,,,,,16384000,4389.696,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
11.801706,2367,343,,,,,,,,,,4000,1689.903,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
18.213955,2464,378,,,,,,,,,,80,32.468,Pinned,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
18.223979,491455,568,,,,,,,,,,6021120,12251.620,Pinned,Device,NVIDIA A100-SXM4-40GB (0),1,13,[CUDA memcpy HtoD]
18.225737,2464,631,,,,,,,,,,20736,8415.584,Device,,NVIDIA A100-SXM4-40GB (0),1,85,[CUDA memset]
18.225762,2368,632,,,,,,,,,,20736,8756.757,Device,,NVIDIA A100-SXM4-40GB (0),1,86,[CUDA memset]
18.225775,2112,633,,,,,,,,,,20736,9818.182,Device,,NVIDIA A100-SXM4-40GB (0),1,87,[CUDA memset]
18.225794,2400,634,,,,,,,,,,20736,8640.000,Device,,NVIDIA A100-SXM4-40GB (0),1,88,[CUDA memset]
18.226130,2144,665,,,,,,,,,,112,52.239,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
18.237985,167520,2342,946,2,1,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)"
18.238544,166048,2348,946,2,1,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)"
18.238954,166335,2354,946,2,1,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)"
18.239355,74559,2360,60,2,1,512,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)"
18.239444,160255,2362,946,2,1,8,8,1,76,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void explicit_convolve_sgemm<float, int, 128, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)"
18.240002,183680,2377,946,2,1,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)"
18.240230,17152,2382,7563,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
18.240451,9824,2388,7563,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
18.240774,14336,2397,1823,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
18.276433,547199,2416,228,6,1,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)"
18.277182,544767,2422,228,6,1,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)"
18.278555,5664,2428,23,2,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.278584,4224,2430,1,2,192,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.278666,88960,2434,3,29,1,128,1,1,255,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)"
18.279098,8736,2438,23,6,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
18.279281,69216,2444,15,7,1,512,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)"
18.279353,457759,2446,228,6,1,8,8,1,63,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)"
18.280077,14272,2455,192,64,1,5,5,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void flip_filter<float, float>(float*, float const*, int, int, int, int)"
18.280135,48159,2457,768,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_32x32<float, false, 5u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.280184,20992,2459,40,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,77,"void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.280411,265759,2473,3,1,544,256,1,1,90,17408,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_cgemm_64x64_tn
18.280680,22080,2475,120,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)"
18.280939,54783,2491,768,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_32x32<float, false, 5u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.281000,14303,2494,40,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,77,"void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.281091,110816,2501,3,1,544,128,1,1,126,18432,0,,,,,NVIDIA A100-SXM4-40GB (0),1,77,ampere_gcgemm_64x32_nt
18.281205,22080,2503,120,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,77,"void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)"
18.281455,22463,2527,2,64,1,936,1,1,32,48672,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.281484,11871,2528,1,192,1,64,13,1,40,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
18.281559,124351,2536,2,2,169,256,1,1,118,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nn
18.281686,36896,2538,2,192,1,936,1,1,32,33696,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
18.281941,21824,2548,2,64,1,936,1,1,32,48672,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.281964,12225,2549,1,192,1,64,13,1,40,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
18.281995,124415,2557,2,2,169,256,1,1,118,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nn
18.282121,36799,2559,2,192,1,936,1,1,32,33696,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
18.282159,13856,2564,5468,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
18.282182,7839,2570,5468,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
18.282294,11264,2579,1268,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
18.283937,346303,2598,53,12,1,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)"
18.284476,346015,2604,53,12,1,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)"
18.285455,4864,2610,6,6,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.285468,9824,2612,1,6,384,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.285581,64672,2616,3,27,1,128,1,1,177,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 64> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 5> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 64> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 5>::Params)"
18.285787,64129,2624,4,7,1,512,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)"
18.285853,254367,2626,27,3,1,8,32,1,80,6400,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)"
18.286348,71519,2635,384,192,1,3,3,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void flip_filter<float, float>(float*, float const*, int, int, int, int)"
18.286420,2271,2639,12,10,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,77,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.286422,93728,2637,12,384,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.286518,198784,2653,6,1,144,128,1,1,94,13312,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_cgemm_64x32_tn
18.286718,16992,2655,240,1,1,256,1,1,40,0,8704,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)"
18.286966,317630,2671,4608,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.287284,25664,2674,120,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,77,"void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.287312,572511,2681,6,1,544,128,1,1,126,18432,0,,,,,NVIDIA A100-SXM4-40GB (0),1,77,ampere_gcgemm_64x32_nt
18.287888,30112,2683,240,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,77,"void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)"
18.288208,7584,2706,12,48,1,32,4,1,32,8704,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)"
18.288287,165568,2708,120,2,1,256,1,1,126,49152,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1
18.288658,9248,2713,1,192,1,256,1,1,48,22656,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.288693,9120,2714,6,48,1,32,8,1,32,9216,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
18.288750,102432,2722,2,3,36,256,1,1,118,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nn
18.288855,19456,2724,1,384,1,256,1,1,64,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
18.289514,10240,2735,1,192,1,256,1,1,48,22656,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.289533,11392,2736,6,48,1,32,8,1,32,9216,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
18.289565,102367,2744,2,3,36,256,1,1,118,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nn
18.289668,18303,2746,1,384,1,256,1,1,64,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
18.289689,8320,2751,2535,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
18.289714,5153,2757,2535,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
18.291606,393215,2777,53,8,1,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)"
18.292185,389631,2783,53,8,1,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)"
18.293194,6336,2789,6,12,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.293208,11840,2791,1,12,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.293298,2624,2793,,,,,,,,,,432,164.634,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.293369,77664,2796,2,27,2,128,1,1,177,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 64> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 5> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 64> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 5>::Params)"
18.293636,77600,2804,4,14,1,512,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)"
18.293716,330463,2806,53,8,1,8,8,1,63,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)"
18.294248,95199,2815,256,384,1,3,3,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void flip_filter<float, float>(float*, float const*, int, int, int, int)"
18.294343,2143,2819,24,10,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,77,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.294345,127647,2817,24,256,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.294476,292512,2833,4,1,144,128,1,1,94,13312,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_cgemm_64x32_tn
18.294771,13248,2835,160,1,1,256,1,1,40,0,8704,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)"
18.294983,423710,2851,6144,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.295406,35328,2854,240,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,77,"void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.295444,764830,2861,4,1,544,128,1,1,126,18432,0,,,,,NVIDIA A100-SXM4-40GB (0),1,77,ampere_gcgemm_64x32_nt
18.296212,22912,2863,160,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,77,"void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)"
18.296496,8576,2886,8,96,1,32,4,1,32,8704,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)"
18.296523,214783,2888,80,2,1,256,1,1,130,49152,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1
18.296930,13472,2893,1,384,1,256,1,1,48,22656,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.296945,12480,2894,12,32,1,32,8,1,32,9216,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
18.296983,194527,2902,2,2,36,256,1,1,118,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nn
18.297179,11393,2904,1,256,1,256,1,1,64,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
18.298013,11136,2915,8,96,1,32,4,1,32,8704,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)"
18.298026,214719,2917,80,2,1,256,1,1,130,49152,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1
18.298243,7360,2921,1690,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
18.298254,4255,2927,1690,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
18.298975,264159,2943,53,8,1,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)"
18.299445,261344,2949,53,8,1,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)"
18.300299,5568,2955,6,8,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.300312,8863,2957,1,8,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.300434,47521,2961,4,27,1,128,1,1,128,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 64, 64> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 64, 64> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)"
18.300629,66272,2969,4,10,1,512,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)"
18.300697,213983,2971,53,8,1,8,8,1,63,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)"
18.301107,63967,2980,256,256,1,3,3,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void flip_filter<float, float>(float*, float const*, int, int, int, int)"
18.301171,2303,2984,16,10,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,77,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.301173,84800,2982,16,256,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.301262,198496,2998,4,1,144,128,1,1,94,13312,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_cgemm_64x32_tn
18.301462,13279,3000,160,1,1,256,1,1,40,0,8704,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)"
18.301742,279262,3016,4096,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.302022,31200,3019,160,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,77,"void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.302056,514526,3026,4,1,544,128,1,1,126,18432,0,,,,,NVIDIA A100-SXM4-40GB (0),1,77,ampere_gcgemm_64x32_nt
18.302574,23327,3028,160,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,77,"void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)"
18.302848,7328,3051,8,64,1,32,4,1,32,8704,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)"
18.302863,146720,3053,80,2,1,256,1,1,130,49152,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1
18.303194,10944,3058,1,256,1,256,1,1,48,22656,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.303207,8896,3059,8,32,1,32,8,1,32,9216,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
18.303233,132896,3067,2,2,36,256,1,1,118,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nn
18.303369,14976,3069,1,256,1,256,1,1,64,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
18.303594,8607,3079,8,64,1,32,4,1,32,8704,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)"
18.303617,146687,3081,80,2,1,256,1,1,130,49152,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1
18.303766,7136,3085,1690,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
18.303775,4192,3091,1690,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
18.303793,5952,3100,360,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
18.304120,17024,3112,2560,1,1,32,8,1,40,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::adaptive_average_pool<float>(float*, float*, int, int, int, int, long, long, long)"
18.304533,4512,3138,360,1,1,256,1,1,31,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<unsigned char, unsigned int>, unsigned int, float, at::PhiloxCudaState)"
18.305468,4704,3149,160,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
18.305582,2912,3170,,,,,,,,,,112,38.462,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
18.309237,155520,4839,8,2,4,128,1,1,255,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x64_32x3_tn_align4>(cutlass_80_tensorop_s1688gemm_256x64_32x3_tn_align4::Params)
18.309394,4192,4841,320,1,1,128,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*)"
18.309400,2432,4848,160,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
18.309524,4096,4875,160,1,1,256,1,1,31,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<unsigned char, unsigned int>, unsigned int, float, at::PhiloxCudaState)"
18.309636,4480,4882,160,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
18.309703,64512,4893,8,2,4,128,1,1,255,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x64_32x3_tn_align4>(cutlass_80_tensorop_s1688gemm_256x64_32x3_tn_align4::Params)
18.309769,4064,4895,320,1,1,128,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*)"
18.309782,2496,4902,160,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
18.309909,4256,4910,40,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
18.310034,20513,4921,8,2,5,128,1,1,96,0,98304,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4>(cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4::Params)
18.310057,3360,4923,79,1,1,128,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*)"
18.310446,4704,4933,3,1,1,32,4,1,80,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)"
18.314022,4736,4946,1,1,1,32,1,1,34,256,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)"
18.314509,22272,4954,10,1,1,1024,1,1,32,128,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::gatherTopK<float, unsigned int, 2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, unsigned int, unsigned int, unsigned int, unsigned int, at::cuda::detail::TensorInfo<float, unsigned int>, unsigned int, unsigned int, at::cuda::detail::TensorInfo<long, unsigned int>, unsigned int)"
18.314636,8160,4957,10,1,1,16,1,1,25,416,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::bitonicSortKVInPlace<float, long, 2, -1, GTComp<float, true>, unsigned int, 32>(at::cuda::detail::TensorInfo<float, unsigned int>, unsigned int, unsigned int, unsigned int, at::cuda::detail::TensorInfo<long, unsigned int>, unsigned int, GTComp<float, true>)"
18.314884,4064,4970,1,1,1,64,1,1,26,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::CompareEqFunctor<long>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::CompareEqFunctor<long>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
18.315041,4576,4981,1,1,1,64,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast)"
18.315234,5312,4994,1,1,1,8,1,1,28,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
18.315410,2400,5000,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
18.315475,3489,5011,1,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#22}::operator()() const::{lambda(bool)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#22}::operator()() const::{lambda(bool)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
18.315554,2656,5024,1,1,1,64,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast)"
18.315606,4928,5037,1,1,1,32,1,1,28,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
18.315634,2016,5043,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
18.315733,3648,5050,,,,,,,,,,4,1.096,Device,Pageable,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoH]
18.315885,2048,5060,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
18.315966,2177,5067,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2>)"
18.316047,2113,5073,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
18.316081,2112,5082,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
18.316109,2111,5089,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2>)"
18.316129,2080,5095,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
18.316639,1953,5107,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
18.317535,2208,5119,,,,,,,,,,40000,18115.942,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.317583,3872,5123,1,1,1,32,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)"
18.317706,5536,5135,3,1,1,32,4,1,107,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)"
18.317849,2624,5161,,,,,,,,,,112,42.683,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
18.321223,21088,6829,8,8,1,128,1,1,106,0,98304,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x6_nn_align4>(cutlass_80_tensorop_s1688gemm_64x64_32x6_nn_align4::Params)
18.321399,24129,6840,32,32,1,256,1,1,57,16384,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x32_nt
18.321480,6369,6851,2,1,1,32,4,1,52,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
18.321777,2560,6865,160,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
18.321905,68703,6881,8,2,4,128,1,1,234,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x64_32x3_nn_align4>(cutlass_80_tensorop_s1688gemm_256x64_32x3_nn_align4::Params)
18.321976,3487,6883,320,1,1,128,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*)"
18.322014,63456,6894,32,64,1,128,1,1,122,12288,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x64_nt
18.322079,5728,6905,8,1,1,32,4,1,52,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
18.322186,2880,6921,160,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3>)"
18.322230,2816,6929,160,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
18.322347,2496,6943,,,,,,,,,,288,115.385,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.322383,130559,6946,8,9,3,128,1,1,154,0,73728,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x64_16x6_nn_align4>(cutlass_80_tensorop_s1688gemm_128x64_16x6_nn_align4::Params)
18.322515,134879,6957,72,64,1,128,1,1,122,12288,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x64_nt
18.322652,5792,6968,8,1,1,32,4,1,52,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
18.322660,3200,6984,360,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3>)"
18.322666,2240,6998,360,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
18.322678,16288,7003,2560,1,1,32,8,1,30,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::atomic_adaptive_average_gradinput<float>(float*, float*, int, int, int, int)"
18.322800,3424,7013,1690,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
18.322852,17088,7020,1,10,256,256,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
18.322984,5312,7028,1690,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
18.323036,16320,7042,16,1,1,32,16,1,28,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
18.323521,2464,7093,,,,,,,,,,20736,8415.584,Device,,NVIDIA A100-SXM4-40GB (0),1,97,[CUDA memset]
18.323531,2207,7094,,,,,,,,,,20736,9395.560,Device,,NVIDIA A100-SXM4-40GB (0),1,98,[CUDA memset]
18.323539,2592,7095,,,,,,,,,,20736,8000.000,Device,,NVIDIA A100-SXM4-40GB (0),1,99,[CUDA memset]
18.323545,2145,7096,,,,,,,,,,20736,9667.133,Device,,NVIDIA A100-SXM4-40GB (0),1,100,[CUDA memset]
18.323722,2080,7127,,,,,,,,,,112,53.846,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
18.330232,3712,8804,1690,1,1,256,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)"
18.330276,219296,8806,36,6,10,8,8,1,86,3328,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)"
18.330987,3648,8812,1690,1,1,256,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)"
18.331005,219232,8814,36,6,10,8,8,1,86,3328,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)"
18.331951,8928,8820,1,8,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.331976,4224,8822,6,8,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.332113,51489,8826,4,27,1,128,1,1,130,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 64, 64> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 64, 64> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)"
18.332467,67199,8836,16,256,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.332534,20320,8838,16,10,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.332562,198368,8852,4,1,144,128,1,1,94,13312,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_cgemm_64x32_tn
18.332762,13183,8854,160,1,1,256,1,1,40,0,8704,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)"
18.333036,280318,8870,4096,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.333317,32352,8873,160,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.333353,515486,8880,4,1,544,128,1,1,126,18432,0,,,,,NVIDIA A100-SXM4-40GB (0),1,89,ampere_gcgemm_64x32_nt
18.333872,22784,8882,160,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)"
18.334168,6720,8905,8,64,1,32,4,1,32,8704,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)"
18.334183,147264,8907,80,2,1,256,1,1,130,49152,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1
18.334548,10624,8912,1,256,1,256,1,1,48,22656,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.334561,8096,8913,8,32,1,32,8,1,32,9216,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
18.334638,131488,8921,2,2,36,256,1,1,118,16384,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nt
18.334771,14400,8923,1,256,1,256,1,1,64,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
18.335010,7264,8933,8,64,1,32,4,1,32,8704,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)"
18.335020,146688,8935,80,2,1,256,1,1,130,49152,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1
18.339384,3264,8952,,,,,,,,,,2359296,722823.529,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.339455,224895,8953,72,8,10,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
18.339962,3200,8959,,,,,,,,,,2359296,737280.000,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.339977,225344,8960,72,8,10,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
18.340657,4384,8966,6,8,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.340678,4256,8968,6,8,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.340701,4512,8970,,,,,,,,,,4719056,1045890.071,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.340735,2368,8971,,,,,,,,,,432,182.432,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.340797,46719,8974,18,2,3,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
18.340845,8992,8978,1,8,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
18.341014,4960,8986,10,256,1,13,13,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void flip_filter<float, float>(float*, float const*, int, int, int, int)"
18.341023,8191,8988,1,256,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.341031,8992,8990,1,256,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.341092,123488,9004,4,4,144,256,1,1,90,17408,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_cgemm_64x64_tn
18.341217,94303,9006,4096,1,1,256,1,1,40,0,8704,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)"
18.341583,2272,9012,1,13,1,256,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)
18.341607,2496,9013,2,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)
18.341639,3264,9014,,,,,,,,,,2359296,722823.529,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.341660,2528,9015,,,,,,,,,,2592,1025.316,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.341681,183871,9016,18,4,13,128,1,1,128,32768,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_scudnn_128x64_stridedB_splitK_small_nn_v1
18.342133,8448,9022,16,10,1,256,1,1,64,24704,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.342178,6464,9023,16,10,1,256,1,1,64,16896,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)"
18.342237,85920,9031,2,2,36,256,1,1,118,16384,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nt
18.342325,10527,9033,8,32,1,32,8,1,62,9216,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)"
18.343129,3328,9045,,,,,,,,,,2359296,708923.077,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.343141,225184,9046,72,8,10,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
18.343369,5408,9057,1690,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
18.343376,16192,9071,16,1,1,32,16,1,28,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
18.345208,4640,9097,2535,1,1,256,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)"
18.345220,312960,9099,54,6,10,8,8,1,86,3328,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)"
18.345730,4447,9105,2535,1,1,256,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)"
18.345739,307359,9107,54,6,10,8,8,1,86,3328,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)"
18.346515,11936,9113,1,12,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.346530,4224,9115,6,8,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.346596,80800,9119,6,14,1,128,1,1,215,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 5> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 5>::Params)"
18.346872,108543,9129,16,384,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.346981,20384,9131,16,10,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.347003,262271,9145,6,1,144,128,1,1,94,13312,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_cgemm_64x32_tn
18.347267,17535,9147,240,1,1,256,1,1,40,0,8704,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)"
18.347508,421950,9163,6144,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.347930,32064,9166,160,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.347965,755071,9173,6,1,544,128,1,1,126,18432,0,,,,,NVIDIA A100-SXM4-40GB (0),1,89,ampere_gcgemm_64x32_nt
18.348724,30560,9175,240,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)"
18.349025,8352,9198,12,64,1,32,4,1,32,8704,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)"
18.349042,217216,9200,120,2,1,256,1,1,126,49152,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1
18.349437,11264,9205,1,256,1,256,1,1,48,22656,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.349450,12480,9206,12,32,1,32,8,1,32,9216,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
18.349473,131968,9214,2,3,36,256,1,1,118,16384,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nt
18.349607,15424,9216,1,384,1,256,1,1,64,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
18.349767,12032,9226,1,256,1,256,1,1,48,22656,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.349780,14144,9227,12,32,1,32,8,1,32,9216,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
18.349802,132128,9235,2,3,36,256,1,1,118,16384,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nt
18.349936,15424,9237,1,384,1,256,1,1,64,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
18.350264,4192,9254,,,,,,,,,,3538944,844213.740,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.350288,308575,9255,54,1,10,8,32,1,117,10496,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
18.350798,4128,9261,,,,,,,,,,3538944,857302.326,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.350810,308159,9262,54,1,10,8,32,1,117,10496,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
18.351545,5793,9268,6,12,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.351559,4385,9270,6,8,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.351605,64000,9274,54,2,1,128,1,1,205,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 64> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 64, 64> >, false, 3> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 64> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 64, 64> >, false, 3>::Params)"
18.351671,11903,9278,1,12,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
18.351882,5632,9286,10,256,1,13,13,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void flip_filter<float, float>(float*, float const*, int, int, int, int)"
18.351892,9120,9288,1,256,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.351906,11264,9290,1,384,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.351974,179391,9304,4,6,144,256,1,1,90,17408,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_cgemm_64x64_tn
18.352155,138623,9306,6144,1,1,256,1,1,40,0,8704,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)"
18.352543,2304,9312,1,13,1,256,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)
18.352556,2496,9313,2,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)
18.352587,4064,9314,,,,,,,,,,3538944,870803.150,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.352602,2656,9315,,,,,,,,,,3888,1463.855,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.352615,248383,9316,27,4,13,128,1,1,128,32768,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_scudnn_128x64_stridedB_splitK_small_nn_v1
18.353076,11296,9322,24,10,1,256,1,1,64,24704,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.353091,7008,9323,16,10,1,256,1,1,64,16896,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)"
18.353127,86401,9331,3,2,36,256,1,1,118,16384,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nt
18.353216,17249,9333,12,32,1,32,8,1,62,9216,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)"
18.354252,13025,9345,24,10,1,256,1,1,64,24704,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.354266,7969,9346,16,10,1,256,1,1,64,16896,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)"
18.354288,86592,9354,3,2,36,256,1,1,118,16384,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nt
18.354376,15936,9356,12,32,1,32,8,1,62,9216,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)"
18.354393,9247,9367,2535,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
18.354426,15936,9381,24,1,1,32,16,1,28,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
18.356384,3327,9407,1268,1,1,256,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)"
18.356403,244799,9409,27,6,10,8,8,1,86,3328,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)"
18.356834,3200,9415,1268,1,1,256,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)"
18.356843,237375,9417,27,6,10,8,8,1,86,3328,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)"
18.357610,9825,9423,1,6,384,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.357626,5184,9425,6,12,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.357673,2400,9427,,,,,,,,,,336,140.000,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.357701,69792,9430,3,14,2,128,1,1,214,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 5> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 5>::Params)"
18.357989,78015,9440,24,192,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.358067,23391,9442,24,10,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.358092,198879,9456,3,1,144,128,1,1,94,13312,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_cgemm_64x32_tn
18.358293,12896,9458,120,1,1,256,1,1,40,0,8704,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)"
18.358508,315678,9474,4608,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.358823,36000,9477,240,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.358862,585599,9484,3,1,544,128,1,1,126,18432,0,,,,,NVIDIA A100-SXM4-40GB (0),1,89,ampere_gcgemm_64x32_nt
18.359451,21600,9486,120,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)"
18.359706,7265,9509,6,96,1,32,4,1,32,8704,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)"
18.359718,212096,9511,60,2,1,256,1,1,130,49152,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1
18.360193,14367,9516,1,384,1,256,1,1,48,22656,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.360211,10560,9517,6,48,1,32,8,1,32,9216,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
18.360244,192800,9525,2,2,36,256,1,1,118,16384,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nt
18.360438,9536,9527,1,192,1,256,1,1,64,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
18.360672,8896,9537,6,96,1,32,4,1,32,8704,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)"
18.360683,212895,9539,60,2,1,256,1,1,130,49152,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1
18.361176,3712,9555,,,,,,,,,,2654208,715034.483,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.361204,251295,9556,54,12,10,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
18.361644,3584,9562,,,,,,,,,,2654208,740571.429,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.361655,249472,9563,54,12,10,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
18.362368,4287,9569,6,6,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.362381,5153,9571,6,12,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.362395,60256,9575,27,3,1,128,1,1,205,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 64> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 64, 64> >, false, 3> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 64> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 64, 64> >, false, 3>::Params)"
18.362457,9856,9579,1,6,384,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
18.363184,6880,9587,10,384,1,13,13,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void flip_filter<float, float>(float*, float const*, int, int, int, int)"
18.363195,6175,9589,1,384,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.363201,8576,9591,1,192,1,256,1,1,32,0,9792,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)"
18.363259,136543,9605,6,3,144,256,1,1,90,17408,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_cgemm_64x64_tn
18.363397,104928,9607,4608,1,1,256,1,1,40,0,8704,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)"
18.363739,2336,9613,1,13,1,256,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)
18.363756,2464,9614,2,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)
18.363769,3552,9615,,,,,,,,,,2654208,747243.243,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.363779,2560,9616,,,,,,,,,,3024,1181.250,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.363788,211775,9617,14,6,13,128,1,1,128,32768,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_scudnn_128x64_stridedB_splitK_small_nn_v1
18.364213,8448,9623,12,10,1,256,1,1,64,24704,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.364224,10656,9624,24,10,1,256,1,1,64,16896,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)"
18.364251,85920,9632,2,3,36,256,1,1,118,16384,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nt
18.364339,12384,9634,6,48,1,32,8,1,62,9216,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)"
18.365143,9120,9646,12,10,1,256,1,1,64,24704,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.365159,11072,9647,24,10,1,256,1,1,64,16896,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)"
18.365194,85856,9655,2,3,36,256,1,1,118,16384,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nt
18.365282,10912,9657,6,48,1,32,8,1,62,9216,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)"
18.365294,7040,9670,5468,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
18.365307,42528,9677,3,10,192,256,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
18.365352,10112,9685,5468,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
18.365388,50944,9699,12,1,1,32,16,1,28,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
18.366161,3871,9721,1823,1,1,256,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)"
18.366171,423935,9723,25,23,10,8,8,1,86,3328,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)"
18.366784,3776,9729,1823,1,1,256,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)"
18.366794,419615,9731,25,23,10,8,8,1,86,3328,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)"
18.367948,4288,9737,1,2,192,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.367963,6752,9739,23,6,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.368019,2464,9741,,,,,,,,,,456,185.065,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.368060,107872,9744,1,57,3,128,1,1,214,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 5, 5, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 5, 5, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 5, 5, false>, 5> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 5, 5, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 5, 5, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, 4, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 5, 5, false>, 5>::Params)"
18.368375,44703,9754,768,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_32x32<float, false, 5u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.368420,31744,9756,120,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.368454,151488,9770,1,1,544,128,1,1,94,13312,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_cgemm_64x32_tn
18.368607,12448,9772,40,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)"
18.368829,42655,9788,768,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_32x32<float, false, 5u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.368871,32000,9791,120,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.368905,117887,9798,1,1,544,128,1,1,126,18432,0,,,,,NVIDIA A100-SXM4-40GB (0),1,89,ampere_gcgemm_64x32_nt
18.369026,12128,9800,40,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)"
18.369231,40064,9824,2,192,1,936,1,1,32,48672,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.369273,12192,9825,1,192,1,64,13,1,40,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
18.369287,193375,9833,2,1,169,256,1,1,118,16384,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nt
18.369482,16192,9835,2,64,1,936,1,1,32,33696,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
18.369703,43551,9855,768,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_32x32<float, false, 5u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.369747,31040,9858,120,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.369780,118080,9865,1,1,544,128,1,1,126,18432,0,,,,,NVIDIA A100-SXM4-40GB (0),1,89,ampere_gcgemm_64x32_nt
18.369900,12096,9867,40,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)"
18.370210,2688,9901,,,,,,,,,,1228800,457142.857,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.370230,503999,9902,50,6,20,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
18.370954,2656,9908,,,,,,,,,,1228800,462650.602,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.370978,506751,9909,50,6,20,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
18.371895,4704,9915,23,2,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.371909,7968,9917,23,6,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.371940,8672,9919,,,,,,,,,,9830400,1133579.336,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.371988,97696,9922,4,4,8,256,1,1,240,0,73728,,,,,NVIDIA A100-SXM4-40GB (0),1,7,_ZN7cutlass6KernelINS_4conv6ke_1...
18.372087,5855,9925,48,13,1,32,4,1,35,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)"
18.372095,4609,9928,1,2,192,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
18.372304,19903,9936,10,192,1,27,27,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void flip_filter<float, float>(float*, float const*, int, int, int, int)"
18.372324,2399,9940,40,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.372326,19360,9938,120,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.372396,90688,9954,3,1,544,256,1,1,90,17408,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_cgemm_64x64_tn
18.372489,72864,9956,768,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)"
18.372810,2336,9962,1,27,1,256,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)
18.372827,2528,9963,2,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)
18.372840,2720,9964,,,,,,,,,,1228800,451764.706,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.372852,2176,9965,,,,,,,,,,7800,3584.559,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.372880,406463,9966,13,6,27,128,1,1,128,9472,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_scudnn_128x32_stridedB_splitK_small_nn_v1
18.373498,21824,9972,2,64,1,936,1,1,32,48672,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
18.373526,29824,9973,36,16,1,624,1,1,40,32448,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradDelta9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)"
18.373590,150079,9981,2,1,169,256,1,1,118,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x128_nn
18.373741,21600,9983,12,16,1,208,4,1,29,16640,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)"
18.374029,21120,9996,10,192,1,27,27,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void flip_filter<float, float>(float*, float const*, int, int, int, int)"
18.374052,9599,9998,120,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.374061,16512,10000,40,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,89,"void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)"
18.374133,90688,10014,3,1,544,256,1,1,90,17408,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_cgemm_64x64_tn
18.374225,72384,10016,768,1,1,512,1,1,64,0,35904,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)"
18.374300,9505,10029,7563,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
18.374311,53823,10036,12,10,64,256,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
18.374367,11360,10044,7563,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
18.374381,17984,10057,64,1,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
18.374646,2208,10081,,,,,,,,,,92928,42086.957,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.374657,185503,10082,12,2,60,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
18.375047,2144,10088,,,,,,,,,,92928,43343.284,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.375057,173696,10089,12,2,60,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
18.375523,7136,10102,,,,,,,,,,8028160,1125022.422,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.375629,50336,10103,216,1,1,1024,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)2>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)"
18.375681,17408,10105,95,2,10,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
18.375700,4288,10107,,,,,,,,,,3345408,780179.104,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.375706,65792,10110,4,1,27,128,1,1,168,0,73728,,,,,NVIDIA A100-SXM4-40GB (0),1,7,_ZN7cutlass6KernelINS_4conv6ke_2...
18.375773,5728,10113,16,4,1,32,4,1,35,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)"
18.375781,16160,10123,216,1,1,1024,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)0>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)"
18.375967,2208,10130,,,,,,,,,,92928,42086.957,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.375977,189696,10131,12,2,60,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
18.376377,2176,10144,,,,,,,,,,92928,42705.882,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
18.376388,177279,10145,12,2,60,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
18.376958,2849,10162,91,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377087,2464,10173,,,,,,,,,,92928,37714.286,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.377214,2208,10178,91,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377239,2400,10184,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377271,2144,10195,,,,,,,,,,256,119.403,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.377292,2080,10200,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377335,6272,10206,1200,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377412,3872,10217,,,,,,,,,,1228800,317355.372,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.377480,3680,10222,1200,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377517,2591,10228,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377550,2176,10239,,,,,,,,,,768,352.941,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.377571,2177,10244,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377586,9440,10250,2592,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377617,5152,10261,,,,,,,,,,2654208,515180.124,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.377637,5120,10266,2592,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377652,2496,10272,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377673,1984,10283,,,,,,,,,,1536,774.194,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.377689,2048,10288,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377712,10976,10294,3456,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377733,5152,10305,,,,,,,,,,3538944,686906.832,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.377750,5824,10310,3456,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377764,2496,10316,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377783,2208,10327,,,,,,,,,,1024,463.768,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.377808,2080,10332,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377822,9152,10338,2304,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377848,4896,10349,,,,,,,,,,2359296,481882.353,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.377866,4640,10354,2304,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377880,2496,10360,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377934,2176,10371,,,,,,,,,,1024,470.588,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.377960,2080,10376,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.377976,338624,10382,147456,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.379464,237439,10397,,,,,,,,,,150994944,635931.519,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.379703,335904,10402,147456,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.380041,2656,10408,16,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.380045,2208,10419,,,,,,,,,,16384,7420.290,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.380048,2112,10424,16,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.380052,153024,10430,65536,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.380206,106847,10441,,,,,,,,,,67108864,628083.746,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.380315,151424,10446,65536,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.380468,2784,10452,16,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.380472,2208,10463,,,,,,,,,,16384,7420.290,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.380475,2080,10468,16,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.380479,41376,10474,16000,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.380521,23872,10485,,,,,,,,,,16384000,686327.078,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.380547,31808,10490,16000,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.380581,2560,10496,4,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.380585,1984,10507,,,,,,,,,,4000,2016.129,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
18.380588,2048,10512,4,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
18.380597,4416,10518,,,,,,,,,,4,0.906,Device,Pageable,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoH]
18.380684,3393,10525,,,,,,,,,,4,1.179,Device,Pageable,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoH]
18.380727,3040,10532,,,,,,,,,,4,1.316,Device,Pageable,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoH]
18.380755,2944,10539,,,,,,,,,,4,1.359,Device,Pageable,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoH]
